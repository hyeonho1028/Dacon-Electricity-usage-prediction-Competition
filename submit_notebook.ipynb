{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import eli5 \n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "                                               \n",
    "import warnings\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_process(data):\n",
    "    st = data.copy()\n",
    "    \n",
    "    if num==1:\n",
    "        st.loc[204, 'use_electric'] = np.nan\n",
    "        st.loc[1033, 'use_electric'] = np.nan\n",
    "        st = st.interpolate(limit_direction='both', method='linear').round(3)\n",
    "        st = st[st['date']>='2020-06-05'].reset_index(drop=True)\n",
    "    elif num==3:\n",
    "        st.loc[[538, 945, 946, 947, 1055, 1523, 1524, 1525, 1526, 1535, 1634, 1635, 1636, 1637, 1639, 1640, 1641, 1642, 1643, 1718, 1761, 1762, 1790], 'use_electric'] = np.nan\n",
    "        st = st.interpolate(limit_direction='both', method='linear').round(3)\n",
    "        st.loc[(st['date']>='2020-07-15') & (st['date']<'2020-07-20'), 'use_electric'] = (st.loc[(st['date']>='2020-07-08') & (st['date']<'2020-07-13'), 'use_electric'].values*.7 +\n",
    "                                                                                            st.loc[(st['date']>='2020-08-05') & (st['date']<'2020-08-10'), 'use_electric'].values*.3)\n",
    "        st.loc[[1055], 'use_electric'] = np.nan\n",
    "        st = st.interpolate(limit_direction='both', method='linear').round(3)\n",
    "        st.loc[(st['date']>='2020-08-03') & (st['date']<'2020-08-05'), 'use_electric'] = (st.loc[(st['date']>='2020-07-13') & (st['date']<'2020-07-15'), 'use_electric'].values*.2 + \n",
    "                                                                                            st.loc[(st['date']>='2020-08-10') & (st['date']<'2020-08-12'), 'use_electric'].values*.8)\n",
    "\n",
    "        st.loc[(st['date']>='2020-07-20') & (st['date']<'2020-07-27'), 'use_electric'] = (st.loc[(st['date']>='2020-07-13') & (st['date']<'2020-07-20'), 'use_electric'].values*.6 +\n",
    "                                                                                            st.loc[(st['date']>='2020-08-03') & (st['date']<'2020-08-10'), 'use_electric'].values*.4)\n",
    "\n",
    "        st.loc[(st['date']>='2020-07-27') & (st['date']<'2020-08-03'), 'use_electric'] = (st.loc[(st['date']>='2020-07-20') & (st['date']<'2020-07-27'), 'use_electric'].values*.2 + \n",
    "                                                                                            st.loc[(st['date']>='2020-08-03') & (st['date']<'2020-08-10'), 'use_electric'].values*.8)\n",
    "    elif num==9:\n",
    "        st.loc[[82, 1427], 'use_electric'] = np.nan\n",
    "        st.loc[1087:1097, 'use_electric'] = st.loc[1087:1096, 'use_electric'] + 200\n",
    "        st.loc[1210:1213, 'use_electric'] = st.loc[1210:1213, 'use_electric'] + 200\n",
    "        st.loc[(st['date']>='2020-06-03 06') & (st['date']<'2020-06-03 17'), 'use_electric'] = np.nan\n",
    "    elif num==10:\n",
    "        st.loc[1462, 'use_electric'] = np.nan\n",
    "        st.loc[1893:1894, 'use_electric'] = np.nan\n",
    "        st = st.interpolate(limit_direction='both', method='linear').round(3)\n",
    "        st.loc[(st['date']>'2020-07-27 08') & (st['date']<'2020-07-27 21'), 'use_electric'] = (st.loc[(st['date']>'2020-07-26 08') & (st['date']<'2020-07-26 21'), 'use_electric'].values*0.3 + \n",
    "                                                                                                st.loc[(st['date']>'2020-07-28 08') & (st['date']<'2020-07-28 21'), 'use_electric'].values*0.7)\n",
    "        st.loc[(st['date']>'2020-08-10 08') & (st['date']<'2020-08-10 21'), 'use_electric'] = (st.loc[(st['date']>'2020-08-09 08') & (st['date']<'2020-08-09 21'), 'use_electric'].values*0.3 + \n",
    "                                                                                                st.loc[(st['date']>'2020-08-11 08') & (st['date']<'2020-08-11 21'), 'use_electric'].values*0.7)\n",
    "    elif num==14:\n",
    "        st.loc[494, 'use_electric'] = np.nan\n",
    "    elif num==15:\n",
    "        st.loc[1760, 'use_electric'] = np.nan\n",
    "    elif num==16:\n",
    "        st.loc[[634, 1883], 'use_electric'] = np.nan\n",
    "    elif num==24:\n",
    "        st = st.loc[72:].reset_index(drop=True)\n",
    "    elif num==25:\n",
    "        st.loc[993:995, 'use_electric'] = np.nan\n",
    "        st.loc[(st['date']>='2020-07-27') & (st['date']<'2020-08-01'), 'use_electric'] = (st.loc[(st['date']>='2020-07-20') & (st['date']<'2020-07-25'), 'use_electric'].values*.4 +\n",
    "                                                                                                                st.loc[(st['date']>='2020-08-03') & (st['date']<'2020-08-08'), 'use_electric'].values*.6)\n",
    "    elif num==27:    \n",
    "        st.loc[1644:1648, 'use_electric'] = np.nan\n",
    "    elif (num==31) | (num==33):\n",
    "        st.loc[257, 'use_electric'] = np.nan\n",
    "    elif num==36:\n",
    "        st.loc[438:439, 'use_electric'] = np.nan\n",
    "        st.loc[1733:1736, 'use_electric'] = np.nan\n",
    "    elif num==40:\n",
    "        st.loc[(st['date']>='2020-08-03') & (st['date']<'2020-08-05'), 'use_electric'] = (st.loc[(st['date']>='2020-07-27') & (st['date']<'2020-07-29'), 'use_electric'].values*.4 +\n",
    "                                                                                                                st.loc[(st['date']>='2020-08-10') & (st['date']<'2020-08-12'), 'use_electric'].values*.6)\n",
    "    elif num==42:\n",
    "        st.loc[(st['date']>='2020-07-13') & (st['date']<'2020-07-14'), 'use_electric'] = (st.loc[(st['date']>='2020-07-06') & (st['date']<'2020-07-07'), 'use_electric'].values*.4 +\n",
    "                                                                                                                st.loc[(st['date']>='2020-07-20') & (st['date']<'2020-07-21'), 'use_electric'].values*.6)\n",
    "        st.loc[(st['date']>='2020-08-10') & (st['date']<'2020-08-11'), 'use_electric'] = (st.loc[(st['date']>='2020-08-03') & (st['date']<'2020-08-04'), 'use_electric'].values*.4 +\n",
    "                                                                                                                st.loc[(st['date']>='2020-08-17') & (st['date']<'2020-08-18'), 'use_electric'].values*.6)\n",
    "    elif num==45:\n",
    "        st.loc[817, 'use_electric'] = np.nan\n",
    "        st['use_electric'] = st['use_electric'].interpolate(limit_direction='both', method='linear').round(3)\n",
    "        st.loc[(st['date']>='2020-08-15') & (st['date']<'2020-08-16'), 'use_electric'] = (st.loc[(st['date']>='2020-08-08') & (st['date']<'2020-08-09'), 'use_electric'].values*0.4 +\n",
    "                                                                                                            st.loc[(st['date']>='2020-08-22') & (st['date']<'2020-08-23'), 'use_electric'].values*0.6)\n",
    "    elif num==52:\n",
    "        st.loc[258, 'use_electric'] = np.nan\n",
    "    elif num==53:\n",
    "        st = st.loc[187:].reset_index(drop=True)\n",
    "    elif num==55:\n",
    "        st.loc[1643, 'use_electric'] = np.nan\n",
    "        st.loc[1648:1649, 'use_electric'] = np.nan\n",
    "        st = st.interpolate(limit_direction='both', method='linear').round(3)\n",
    "        st.loc[(st['date']>'2020-8-3 00') & (st['date']<='2020-8-7 23'), 'use_electric'] = st.loc[(st['date']>'2020-7-27 00') & (st['date']<='2020-7-31 23'), 'use_electric'].values*.3 + st.loc[(st['date']>'2020-8-10 00') & (st['date']<='2020-8-14 23'), 'use_electric'].values*.7\n",
    "    elif num==56:\n",
    "        st.loc[(st['date']>'2020-8-3 00') & (st['date']<='2020-8-7 23'), 'use_electric'] = st.loc[(st['date']>'2020-7-27 00') & (st['date']<='2020-7-31 23'), 'use_electric'].values*.3 + st.loc[(st['date']>'2020-8-10 00') & (st['date']<='2020-8-14 23'), 'use_electric'].values*.7\n",
    "    elif num==59:\n",
    "        st.loc[[1816, 1819, 1833, 1834], 'use_electric'] = np.nan\n",
    "    elif num==60:\n",
    "        st.loc[384:387, 'use_electric'] = np.nan\n",
    "        st.loc[605:606, 'use_electric'] = np.nan\n",
    "        st.loc[720:721, 'use_electric'] = np.nan\n",
    "        st.loc[792, 'use_electric'] = np.nan\n",
    "    st['use_electric'] = st['use_electric'].interpolate(limit_direction='both', method='linear').round(3)\n",
    "        \n",
    "    if num in [2,3,6,7,8,9,13,16,17,18,22,23,24,25,26,27,31,33,34,35,37,43,44,46,47,48,52,53,54,55,56,57,58]:\n",
    "        st.loc[(st['date']>='2020-08-17 00') & (st['date']<'2020-08-18 00'), 'use_electric'] = (st.loc[(st['date']>='2020-08-10 00') & (st['date']<'2020-08-11 00'), 'use_electric'].values*.5 + st.loc[(st['date']>='2020-08-24 00') & (st['date']<'2020-08-25 00'), 'use_electric'].values*.5).round(3)\n",
    "    \n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(preds, target):\n",
    "    return mean_absolute_error(target, preds)\n",
    "def mse(preds, target):\n",
    "    return mean_squared_error(target, preds)\n",
    "def smape(preds, target):\n",
    "    '''\n",
    "    Function to calculate SMAPE\n",
    "    '''\n",
    "    n = len(preds)\n",
    "    masked_arr = ~((preds==0)&(target==0))\n",
    "    preds, target = preds[masked_arr], target[masked_arr]\n",
    "    num = np.abs(preds-target)\n",
    "    denom = np.abs(preds)+np.abs(target)\n",
    "    smape_val = (200*np.sum(num/denom))/n\n",
    "    return smape_val\n",
    "\n",
    "def lgbm_smape(preds, train_data):\n",
    "    '''\n",
    "    Custom Evaluation Function for LGBM\n",
    "    '''\n",
    "    # labels = train_data.get_label()\n",
    "    labels = train_data\n",
    "    smape_val = smape(preds, labels)\n",
    "    return 'SMAPE', smape_val, False\n",
    "\n",
    "def lgbm_smape_exp(preds, train_data):\n",
    "    '''\n",
    "    Custom Evaluation Function for LGBM\n",
    "    '''\n",
    "    # labels = train_data.get_label()\n",
    "    labels = train_data\n",
    "    smape_val = smape(np.expm1(preds), np.expm1(labels))\n",
    "    return 'SMAPE', smape_val, False\n",
    "\n",
    "# function for feature engineering\n",
    "def CDH(xs):\n",
    "    ys = []\n",
    "    for i in range(len(xs)):\n",
    "        if i < 11:\n",
    "            ys.append(np.sum(xs[:(i+1)]-26))\n",
    "        else:\n",
    "            ys.append(np.sum(xs[(i-11):(i+1)]-26))\n",
    "    return ys\n",
    "\n",
    "def lgb_models(df_train, df_test, drop_col, target, category_features=[], learn='lasso', v=5000, permu=False, exp=True, gpu=False):\n",
    "    train = df_train.copy()\n",
    "    test = df_test.copy()\n",
    "    TARGET = target\n",
    "    FOLDS = train['fold_num'].nunique()\n",
    "    RANDOM_STATE = 0\n",
    "\n",
    "    oof = np.zeros([len(train)])\n",
    "    pred = np.zeros([len(test)])\n",
    "\n",
    "    features = [col for col in test.columns if col not in drop_col]\n",
    "    feature_importances = np.zeros(len(features))\n",
    "    print('use_feature : ', features)\n",
    "    for idx in np.unique(train['fold_num']):\n",
    "        trn_idx = train[train['fold_num']!=idx].index\n",
    "        val_idx = train[train['fold_num']==idx].index\n",
    "        \n",
    "        X_train = train[features]\n",
    "        X_test = test[features]\n",
    "        y_train = train[TARGET].values\n",
    "        tt = (X_train.loc[trn_idx], y_train[trn_idx])\n",
    "        vv = (X_train.loc[val_idx], y_train[val_idx])\n",
    "\n",
    "        if learn=='lgb':\n",
    "            reg = LGBMRegressor(\n",
    "                                boosting_type='gbdt', #['gbdt', 'dart', 'goss']\n",
    "                                objective='regression', \n",
    "                                # metrics='mse', \n",
    "                                n_estimators=20000,\n",
    "                                max_depth=8,\n",
    "                                learning_rate=0.03,\n",
    "                                colsample_bytree=0.9,\n",
    "                                subsample=0.7,\n",
    "                                num_leaves=256,\n",
    "                                reg_alpha=0.01,\n",
    "                                reg_lambda=0.01,\n",
    "                                n_jobs=-1,\n",
    "                                random_state=RANDOM_STATE,\n",
    "                                )\n",
    "            if exp:\n",
    "                reg.fit(tt[0], tt[1], eval_set=[tt, vv], eval_metric=lgbm_smape_exp, early_stopping_rounds=500, verbose=v, categorical_feature=category_features, )\n",
    "            else:\n",
    "                reg.fit(tt[0], tt[1], eval_set=[tt, vv], eval_metric=lgbm_smape, early_stopping_rounds=500, verbose=v, categorical_feature=category_features, )\n",
    "                \n",
    "            feature_importances += reg.feature_importances_ / FOLDS\n",
    "        elif learn=='xgb':\n",
    "            reg = XGBRegressor(\n",
    "                                objective='reg:squarederror', \n",
    "                                # metrics='mse', \n",
    "                                n_estimators=20000,\n",
    "                                max_depth=8,\n",
    "                                learning_rate=0.03,\n",
    "                                colsample_bytree=0.9,\n",
    "                                subsample=0.7,\n",
    "                                reg_alpha=0.01,\n",
    "                                reg_lambda=0.01,\n",
    "                                n_jobs=-1,\n",
    "                                random_state=RANDOM_STATE,\n",
    "                                )\n",
    "            reg.fit(tt[0], tt[1], eval_set=[tt, vv], early_stopping_rounds=500, verbose=v)\n",
    "\n",
    "        oof[val_idx] = reg.predict(X_train.loc[val_idx])\n",
    "        pred += reg.predict(X_test) / FOLDS\n",
    "\n",
    "        if v>0: print(idx+1, 'fold complete ################################\\n')\n",
    "    \n",
    "    if exp:\n",
    "        print('mae : ', mae(np.expm1(oof), np.expm1(train[TARGET])), 'mse : ', mse(np.expm1(oof), np.expm1(train[TARGET])), 'smape :', smape(np.expm1(oof), np.expm1(train[TARGET])))\n",
    "    else:\n",
    "        print('mae : ', mae(oof, train[TARGET]), 'mse : ', mse(oof, train[TARGET]), 'smape :', smape(oof, train[TARGET]))\n",
    "    feature_importances = pd.DataFrame({'feature':features, 'value':feature_importances}).sort_values('value', ascending=False).reset_index(drop=True)\n",
    "    return oof, pred, feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv', engine='python', encoding='cp949')\n",
    "df_test = pd.read_csv('data/test.csv', engine='python', encoding='cp949')\n",
    "sub = pd.read_csv('data/sample_submission.csv', engine='python', encoding='cp949')\n",
    "\n",
    "# ['num', 'date_time', '전력사용량(kWh)', '기온(°C)', '풍속(m/s)', '습도(%)', '강수량(mm)', '일조(hr)', '비전기냉방설비운영', '태양광보유']\n",
    "df_train.columns = ['num', 'date', 'use_electric', 'temperature', 'wind_speed', 'humidity', 'precipitation', 'sunshine', 'operation', 'solar_power']\n",
    "df_test.columns = ['num', 'date', 'temperature', 'wind_speed', 'humidity', 'precipitation', 'sunshine', 'operation', 'solar_power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train.copy()\n",
    "test = df_test.copy()\n",
    "\n",
    "# 건물별로 '비전기냉방설비운영'과 '태양광보유'를 판단해 test set의 결측치를 보간해줍니다\n",
    "test_fill = test.copy()\n",
    "sp_dict = train[['num', 'solar_power']].drop_duplicates().set_index('num').to_dict()['solar_power']\n",
    "test['solar_power'] = test['num'].map(sp_dict)\n",
    "\n",
    "op_dict = train[['num', 'operation']].drop_duplicates().set_index('num').to_dict()['operation']\n",
    "test['operation'] = test['num'].map(sp_dict)\n",
    "\n",
    "for num in range(1, 61):\n",
    "    for col in ['temperature', 'wind_speed', 'humidity', 'precipitation', 'sunshine']:\n",
    "        test.loc[test['num']==num, col] = test.loc[test['num']==num, col].interpolate().round(1)\n",
    "        \n",
    "for df in [train, test]:\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['date2'] = df['date'].dt.date.astype(str)\n",
    "    df['month'] = df['date'].dt.month - 6\n",
    "    df['week'] = (df['date'].dt.isocalendar()['week'] - 23).astype(int)\n",
    "    df['day'] = df['month']*df['month'].map({0:30, 1:31, 2:31}) + df['date'].dt.day\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['weekday'] = df['date'].dt.weekday\n",
    "    df['weekend'] = (df['weekday']>=5).astype(int)\n",
    "    df['weekend2'] = df['weekday'].map({0:0, 1:0, 2:0, 3:0, 4:0, 5:1, 6:2})\n",
    "    df['holiday'] = df['date2'].isin(['2020-06-06', '2020-08-15', '2020-08-17']).astype(int)\n",
    "    df['weekend_holiday'] = ((df['weekend'] + df['holiday'])>0).astype(int)\n",
    "#     df.loc[df['holiday']==1, 'weekend2'] = 2\n",
    "    \n",
    "    ############## 화씨온도\n",
    "    df['temperature_F'] = (df['temperature'] * 9/5) + 32 \n",
    "\n",
    "    ############## 체감온도, https://www.weather.go.kr/plus/life/li_asset/HELP/basic/help_01_07.jsp\n",
    "    df['temperature2'] = 13.12 + 0.6215*df['temperature'] - 11.37*(df['wind_speed']*3.6)**0.16 + 0.3965*(df['wind_speed']*3.6)**0.16*df['temperature']\n",
    "#     df['diff_temp'] = df['temperature2'] - df['temperature']\n",
    "\n",
    "    ############## 열지수, https://www.weather.go.kr/weather/lifenindustry/li_asset/HELP/basic/help_01_04.jsp\n",
    "    T = df['temperature_F']\n",
    "    RH = df['humidity']\n",
    "    df['heat_index'] = -42.379 + 2.04901523*T + 10.14333127*RH - .22475541*T*RH - .00683783*T*T - .05481717*RH*RH + .00122874*T*T*RH + .00085282*T*RH*RH - .00000199*T*T*RH*RH\n",
    "    df['heat_index'] = (df['heat_index']-32) * 5/9\n",
    "    df.loc[df['heat_index']<32, 'heat_index'] = 0\n",
    "    df.loc[(df['heat_index']>=32) & (df['heat_index']<41), 'heat_index'] = 1\n",
    "    df.loc[(df['heat_index']>=41) & (df['heat_index']<54), 'heat_index'] = 2\n",
    "    df.loc[(df['heat_index']>=54) & (df['heat_index']<66), 'heat_index'] = 3\n",
    "    df.loc[df['heat_index']>=66, 'heat_index'] = 4\n",
    "    \n",
    "    ############## working hour\n",
    "    df['work_hour'] = ((df['hour']>=8) & (df['hour']<=19)).astype(int)\n",
    "    df['lunch_hour'] = ((df['hour']>=11) & (df['hour']<=13) & (df['weekday']<=4)).astype(int)\n",
    "    df['lunch_hour2'] = ((df['hour']>=12) & (df['hour']<=14) & (df['weekday']>4)).astype(int)\n",
    "    \n",
    "    df['dinner_hour'] = ((df['hour']>=17) & (df['hour']<=22)).astype(int)\n",
    "    df['dinner_hour2'] = ((df['hour']>=18) & (df['weekday']>=4) & (df['weekday']<=5)).astype(int)\n",
    "    \n",
    "#     df['religion'] = ((df['hour']>=9) & (df['weekday']<13) & (df['weekday']==6)).astype(int)\n",
    "\n",
    "    ############## 불쾌지수\n",
    "    df['THI'] = 9/5*df['temperature'] - 0.55*(1-df['humidity']/100)*(9/5*df['temperature']-26)+32\n",
    "    df.loc[df['THI']<68, 'THI'] = 0\n",
    "    df.loc[(df['THI']>=68) & (df['THI']<75), 'THI'] = 1\n",
    "    df.loc[(df['THI']>=75) & (df['THI']<80), 'THI'] = 2\n",
    "    df.loc[(df['THI']>=80), 'THI'] = 3\n",
    "    \n",
    "    ############## CDH\n",
    "    cdhs = []\n",
    "    for num in range(1, 61):\n",
    "        temp = df[df['num'] == num]\n",
    "        cdh = CDH(temp['temperature'].values)\n",
    "        cdhs += cdh\n",
    "    else:\n",
    "        df['CDH'] = cdhs\n",
    "\n",
    "test['sunshine'] = np.where(test['sunshine']>1.0, 1.0, test['sunshine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for num in range(1, 61):\n",
    "    st = train[train['num']==num].reset_index(drop=True)\n",
    "    st = target_process(st)\n",
    "    df = pd.concat([df, st])\n",
    "train = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# subset models\n",
    "oof_lgb = {}\n",
    "pred_lgb = {}\n",
    "fea_imp_lgb = {}\n",
    "oof_xgb = {}\n",
    "pred_xgb = {}\n",
    "fea_imp_xgb = {}\n",
    "\n",
    "for num in range(1, 61):\n",
    "    st = train[train['num']==num].reset_index(drop=True)\n",
    "    sub_test = test[test['num']==num].reset_index(drop=True)\n",
    "    drop_cols = ['use_electric', 'num', 'date', 'date2', 'wind_speed', 'precipitation', 'sunshine', 'operation', 'solar_power', 'week', 'weekend', 'weekend_holiday', 'temperature_F', 'temperature2', 'holiday', 'fold_num', 'cluster', 'oof']\n",
    "\n",
    "    new_col = 'mean_use_electric' \n",
    "    st[new_col] = st['weekend'].astype(str) + '_' + st['hour'].astype(str)\n",
    "    sub_test[new_col] = sub_test['weekend'].astype(str) + '_' + sub_test['hour'].astype(str)\n",
    "    sub_test[new_col] = sub_test[new_col].map(st.groupby(new_col)['use_electric'].mean())\n",
    "    st[new_col] = st[new_col].map(st.groupby(new_col)['use_electric'].mean())\n",
    "\n",
    "    st['use_electric'] = np.log1p(st['use_electric'])\n",
    "    st['fold_num'] = (st['day']//7)\n",
    "\n",
    "    print('######################################################################## Learning', num)\n",
    "    oof_lgb[num], pred_lgb[num], fea_imp_lgb[num] = lgb_models(st, sub_test, drop_col=drop_cols, \n",
    "                                                               target='use_electric', \n",
    "                                                               category_features=['month', 'THI', 'weekend2'],\n",
    "                                                               learn='lgb', v=0, permu=False, gpu=False)\n",
    "    \n",
    "    oof_xgb[num], pred_xgb[num], fea_imp_xgb[num] = lgb_models(st, sub_test, drop_col=drop_cols, \n",
    "                                                               target='use_electric', \n",
    "                                                               learn='xgb', v=0, permu=False, gpu=False)\n",
    "    \n",
    "    print('\\n')\n",
    "\n",
    "# copy\n",
    "oof_lgb678 = oof_lgb.copy()\n",
    "oof_xgb678 = oof_xgb.copy()\n",
    "pred_lgb678 = pred_lgb.copy()\n",
    "pred_xgb678 = pred_xgb.copy()\n",
    "\n",
    "for num in range(1, 61):\n",
    "    st = train[train['num']==num].reset_index(drop=True)\n",
    "    sub_test = test[test['num']==num].reset_index(drop=True)\n",
    "    drop_cols = ['use_electric', 'num', 'date', 'date2', 'wind_speed', 'precipitation', 'sunshine', 'operation', 'solar_power', 'week', 'weekend', 'weekend_holiday', 'temperature_F', 'temperature2', 'holiday', 'fold_num', 'cluster', 'oof']\n",
    "\n",
    "    new_col = 'mean_use_electric' \n",
    "    st[new_col] = st['weekend'].astype(str) + '_' + st['hour'].astype(str)\n",
    "    sub_test[new_col] = sub_test['weekend'].astype(str) + '_' + sub_test['hour'].astype(str)\n",
    "    sub_test[new_col] = sub_test[new_col].map(st.groupby(new_col)['use_electric'].mean())\n",
    "    st[new_col] = st[new_col].map(st.groupby(new_col)['use_electric'].mean())\n",
    "    \n",
    "    st = st[st['date']>='2020-07-01'].reset_index(drop=True)\n",
    "    sub_test['day'] = sub_test['day'] - st['day'].min()\n",
    "    st['day'] = st['day'] - st['day'].min()  \n",
    "\n",
    "    st['use_electric'] = np.log1p(st['use_electric'])\n",
    "    st['fold_num'] = (st['day']//7)\n",
    "\n",
    "    print('######################################################################## Learning', num)\n",
    "    oof_lgb[num], pred_lgb[num], fea_imp_lgb[num] = lgb_models(st, sub_test, drop_col=drop_cols, \n",
    "                                                               target='use_electric', \n",
    "                                                               category_features=['month', 'THI', 'weekend2'],\n",
    "                                                               learn='lgb', v=0, permu=False, gpu=False)\n",
    "    \n",
    "    oof_xgb[num], pred_xgb[num], fea_imp_xgb[num] = lgb_models(st, sub_test, drop_col=drop_cols, \n",
    "                                                               target='use_electric', \n",
    "                                                               learn='xgb', v=0, permu=False, gpu=False)\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "oof_lgb78 = oof_lgb.copy()\n",
    "oof_xgb78 = oof_xgb.copy()\n",
    "pred_lgb78 = pred_lgb.copy()\n",
    "pred_xgb78 = pred_xgb.copy()\n",
    "\n",
    "for num in range(1, 61):\n",
    "    st = train[train['num']==num].reset_index(drop=True)\n",
    "    sub_test = test[test['num']==num].reset_index(drop=True)\n",
    "    drop_cols = ['month', 'use_electric', 'num', 'date', 'date2', 'wind_speed', 'precipitation', 'sunshine', 'operation', 'solar_power', 'week', 'weekend', 'weekend_holiday', 'temperature_F', 'temperature2', 'holiday', 'fold_num', 'cluster', 'oof']\n",
    "\n",
    "    new_col = 'mean_use_electric' \n",
    "    st[new_col] = st['weekend'].astype(str) + '_' + st['hour'].astype(str)\n",
    "    sub_test[new_col] = sub_test['weekend'].astype(str) + '_' + sub_test['hour'].astype(str)\n",
    "    sub_test[new_col] = sub_test[new_col].map(st.groupby(new_col)['use_electric'].mean())\n",
    "    st[new_col] = st[new_col].map(st.groupby(new_col)['use_electric'].mean())\n",
    "    \n",
    "    st = st[st['date']>='2020-08-01'].reset_index(drop=True)\n",
    "    sub_test['day'] = sub_test['day'] - st['day'].min()\n",
    "    st['day'] = st['day'] - st['day'].min()\n",
    "\n",
    "    st['use_electric'] = np.log1p(st['use_electric'])\n",
    "    st['fold_num'] = (st['day']//7)\n",
    "\n",
    "    print('######################################################################## Learning', num)\n",
    "    oof_lgb[num], pred_lgb[num], fea_imp_lgb[num] = lgb_models(st, sub_test, drop_col=drop_cols, \n",
    "                                                               target='use_electric', \n",
    "                                                               category_features=['THI', 'weekend2'],\n",
    "                                                               learn='lgb', v=0, permu=False, gpu=False)\n",
    "    \n",
    "    oof_xgb[num], pred_xgb[num], fea_imp_xgb[num] = lgb_models(st, sub_test, drop_col=drop_cols, \n",
    "                                                               target='use_electric', \n",
    "                                                               learn='xgb', v=0, permu=False, gpu=False)\n",
    "    \n",
    "oof_lgb8 = oof_lgb.copy()\n",
    "oof_xgb8 = oof_xgb.copy()\n",
    "pred_lgb8 = pred_lgb.copy()\n",
    "pred_xgb8 = pred_xgb.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6,7,8월\n",
    "print(\n",
    "    smape(np.expm1(np.concatenate([oof_lgb678[num] for num in range(1, 61)])), train['use_electric']),\n",
    "    smape(np.expm1(np.concatenate([oof_xgb678[num] for num in range(1, 61)])), train['use_electric']),\n",
    "    smape(np.expm1(np.concatenate([oof_lgb678[num]*.7 + oof_xgb678[num]*.3 for num in range(1, 61)])), train['use_electric']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7,8월\n",
    "print(\n",
    "    smape(np.expm1(np.concatenate([oof_lgb78[num] for num in range(1, 61)])), train.loc[train['date']>='2020-07-01', 'use_electric'].values),\n",
    "    smape(np.expm1(np.concatenate([oof_xgb78[num] for num in range(1, 61)])), train.loc[train['date']>='2020-07-01', 'use_electric'].values),\n",
    "    smape(np.expm1(np.concatenate([oof_lgb78[num]*.7 + oof_xgb78[num]*.3 for num in range(1, 61)])), train.loc[train['date']>='2020-07-01', 'use_electric'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8월\n",
    "print(\n",
    "    smape(np.expm1(np.concatenate([oof_lgb8[num] for num in range(1, 61)])), train.loc[train['date']>='2020-08-01', 'use_electric'].values),\n",
    "    smape(np.expm1(np.concatenate([oof_xgb8[num] for num in range(1, 61)])), train.loc[train['date']>='2020-08-01', 'use_electric'].values),\n",
    "    smape(np.expm1(np.concatenate([oof_lgb8[num]*.7 + oof_xgb8[num]*.3 for num in range(1, 61)])), train.loc[train['date']>='2020-08-01', 'use_electric'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_best = ((np.concatenate(list(pred_lgb678.values()))*.7 + np.concatenate(list(pred_xgb678.values()))*.3)*.45 +\n",
    "                (np.concatenate(list(pred_lgb78.values()))*.7 + np.concatenate(list(pred_xgb78.values()))*.3)*.45 +\n",
    "                (np.concatenate(list(pred_lgb8.values()))*.7 + np.concatenate(list(pred_xgb8.values()))*.3)*.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train.copy()\n",
    "test = df_test.copy()\n",
    "\n",
    "# 건물별로 '비전기냉방설비운영'과 '태양광보유'를 판단해 test set의 결측치를 보간해줍니다\n",
    "test_fill = test.copy()\n",
    "sp_dict = train[['num', 'solar_power']].drop_duplicates().set_index('num').to_dict()['solar_power']\n",
    "test['solar_power'] = test['num'].map(sp_dict)\n",
    "\n",
    "op_dict = train[['num', 'operation']].drop_duplicates().set_index('num').to_dict()['operation']\n",
    "test['operation'] = test['num'].map(sp_dict)\n",
    "\n",
    "for num in range(1, 61):\n",
    "    for col in ['temperature', 'wind_speed', 'humidity', 'precipitation', 'sunshine']:\n",
    "        test.loc[test['num']==num, col] = test.loc[test['num']==num, col].interpolate().round(1)\n",
    "        \n",
    "for df in [train, test]:\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['date2'] = df['date'].dt.date.astype(str)\n",
    "    df['month'] = df['date'].dt.month - 6\n",
    "    df['week'] = (df['date'].dt.isocalendar()['week'] - 23).astype(int)\n",
    "    df['day'] = df['month']*df['month'].map({0:30, 1:31, 2:31}) + df['date'].dt.day\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['hour2'] = df['date'].dt.hour//6\n",
    "    df['weekday'] = df['date'].dt.weekday\n",
    "    df['weekend'] = (df['weekday']>=5).astype(int)\n",
    "    df['weekend2'] = df['weekday'].map({0:0, 1:0, 2:0, 3:0, 4:0, 5:1, 6:2})\n",
    "    df['holiday'] = df['date2'].isin(['2020-06-06', '2020-08-15', '2020-08-17']).astype(int)\n",
    "    df['weekend_holiday'] = ((df['weekend'] + df['holiday'])>0).astype(int)\n",
    "#     df.loc[df['holiday']==1, 'weekend2'] = 2\n",
    "    \n",
    "    ############## 화씨온도\n",
    "    df['temperature_F'] = (df['temperature'] * 9/5) + 32 \n",
    "\n",
    "    ############## 체감온도, https://www.weather.go.kr/plus/life/li_asset/HELP/basic/help_01_07.jsp\n",
    "    df['temperature2'] = 13.12 + 0.6215*df['temperature'] - 11.37*(df['wind_speed']*3.6)**0.16 + 0.3965*(df['wind_speed']*3.6)**0.16*df['temperature']\n",
    "#     df['diff_temp'] = df['temperature2'] - df['temperature']\n",
    "\n",
    "    ############## 열지수, https://www.weather.go.kr/weather/lifenindustry/li_asset/HELP/basic/help_01_04.jsp\n",
    "    T = df['temperature_F']\n",
    "    RH = df['humidity']\n",
    "    df['heat_index'] = -42.379 + 2.04901523*T + 10.14333127*RH - .22475541*T*RH - .00683783*T*T - .05481717*RH*RH + .00122874*T*T*RH + .00085282*T*RH*RH - .00000199*T*T*RH*RH\n",
    "    df['heat_index'] = (df['heat_index']-32) * 5/9\n",
    "    df.loc[df['heat_index']<32, 'heat_index'] = 0\n",
    "    df.loc[(df['heat_index']>=32) & (df['heat_index']<41), 'heat_index'] = 1\n",
    "    df.loc[(df['heat_index']>=41) & (df['heat_index']<54), 'heat_index'] = 2\n",
    "    df.loc[(df['heat_index']>=54) & (df['heat_index']<66), 'heat_index'] = 3\n",
    "    df.loc[df['heat_index']>=66, 'heat_index'] = 4\n",
    "    \n",
    "    ############## working hour\n",
    "    df['work_hour'] = ((df['hour']>=8) & (df['hour']<=19)).astype(int)\n",
    "    df['lunch_hour'] = ((df['hour']>=11) & (df['hour']<=13) & (df['weekday']<=4)).astype(int)\n",
    "    df['lunch_hour2'] = ((df['hour']>=12) & (df['hour']<=14) & (df['weekday']>4)).astype(int)\n",
    "    \n",
    "    df['dinner_hour'] = ((df['hour']>=17) & (df['hour']<=22)).astype(int)\n",
    "    df['dinner_hour2'] = ((df['hour']>=18) & (df['weekday']>=4) & (df['weekday']<=5)).astype(int)\n",
    "    \n",
    "#     df['religion'] = ((df['hour']>=9) & (df['weekday']<13) & (df['weekday']==6)).astype(int)\n",
    "\n",
    "    ############## 불쾌지수\n",
    "    df['THI'] = 9/5*df['temperature'] - 0.55*(1-df['humidity']/100)*(9/5*df['temperature']-26)+32\n",
    "    df.loc[df['THI']<68, 'THI'] = 0\n",
    "    df.loc[(df['THI']>=68) & (df['THI']<75), 'THI'] = 1\n",
    "    df.loc[(df['THI']>=75) & (df['THI']<80), 'THI'] = 2\n",
    "    df.loc[(df['THI']>=80), 'THI'] = 3\n",
    "    \n",
    "    ############## CDH\n",
    "    cdhs = []\n",
    "    for num in range(1, 61):\n",
    "        temp = df[df['num'] == num]\n",
    "        cdh = CDH(temp['temperature'].values)\n",
    "        cdhs += cdh\n",
    "    else:\n",
    "        df['CDH'] = cdhs\n",
    "\n",
    "test['sunshine'] = np.where(test['sunshine']>1.0, 1.0, test['sunshine'])\n",
    "\n",
    "pivot = pd.pivot_table(data=train, values='use_electric', index='num', columns='date').values\n",
    "scaler = MinMaxScaler()\n",
    "pivot = scaler.fit_transform(pivot.T).T\n",
    "\n",
    "km = KMeans(n_clusters=5, random_state=42, max_iter=1000, )\n",
    "km.fit(pivot)\n",
    "cluster_dict = {num+1:cluster for num, cluster in enumerate(km.labels_)}\n",
    "\n",
    "train['cluster'] = train['num'].map(cluster_dict)\n",
    "test['cluster'] = test['num'].map(cluster_dict)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for num in range(1, 61):\n",
    "    st = train[train['num']==num].reset_index(drop=True)\n",
    "    st = target_process(st)\n",
    "    df = pd.concat([df, st])\n",
    "train = df.reset_index(drop=True)\n",
    "\n",
    "train['region'] = 0 # [1,7,17,20,21,31,34,38,46,47,49,51,52,55,58]\n",
    "train.loc[train['num'].isin([2,5,10,11,19,28,50]), 'region'] = 1\n",
    "train.loc[train['num'].isin([12,35,42,48,60]), 'region'] = 2\n",
    "train.loc[train['num'].isin([22,23,33,40,53]), 'region'] = 3\n",
    "train.loc[train['num'].isin([44, 57]), 'region'] = 4\n",
    "train.loc[train['num'].isin([4, 8, 9, 13, 14, 16, 26, 27, 29, 30, 36, 37, 39, 43, 56, 59]), 'region'] = 5\n",
    "    \n",
    "test['region'] = 0\n",
    "test.loc[test['num'].isin([2,5,10,11,19,28,50]), 'region'] = 1\n",
    "test.loc[test['num'].isin([12,35,42,48,60]), 'region'] = 2\n",
    "test.loc[test['num'].isin([22,23,33,40,53]), 'region'] = 3\n",
    "test.loc[test['num'].isin([44, 57]), 'region'] = 4\n",
    "test.loc[test['num'].isin([4, 8, 9, 13, 14, 16, 26, 27, 29, 30, 36, 37, 39, 43, 56, 59]), 'region'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_split(st, sub_test):\n",
    "    if subset=='afternoon':\n",
    "        st = st[(st['hour']>12)].reset_index(drop=True)\n",
    "        sub_test = sub_test[sub_test['hour']>12].reset_index(drop=True)\n",
    "    elif subset=='morning':\n",
    "        st = st[(st['hour']<13)].reset_index(drop=True)\n",
    "        sub_test = sub_test[sub_test['hour']<13].reset_index(drop=True)\n",
    "    elif subset=='working':\n",
    "        st = st[(st['hour']>=8)&(st['hour']<20)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']>=8)&(sub_test['hour']<20)].reset_index(drop=True)\n",
    "    elif subset=='noworking':\n",
    "        st = st[(st['hour']<8)|(st['hour']>=20)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']<8)|(sub_test['hour']>=20)].reset_index(drop=True)\n",
    "    elif subset=='q1':\n",
    "        st = st[(st['hour']>=0)                  &(st['hour']<7)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']>=0)&(sub_test['hour']<7)].reset_index(drop=True)\n",
    "    elif subset=='q2':\n",
    "        st = st[(st['hour']>=7)                  &(st['hour']<13)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']>=7)&(sub_test['hour']<13)].reset_index(drop=True)\n",
    "    elif subset=='q3':\n",
    "        st = st[(st['hour']>=13)                  &(st['hour']<19)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']>=13)&(sub_test['hour']<19)].reset_index(drop=True)\n",
    "    elif subset=='q4':\n",
    "        st =             st[st['hour']>=19].reset_index(drop=True)\n",
    "        sub_test = sub_test[sub_test['hour']>=19].reset_index(drop=True)\n",
    "    elif subset=='s1':\n",
    "        st = st[(st['hour']>=0)                  &(st['hour']<5)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']>=0)&(sub_test['hour']<5)].reset_index(drop=True)\n",
    "    elif subset=='s2':\n",
    "        st = st[(st['hour']>=5)                  &(st['hour']<9)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']>=5)&(sub_test['hour']<9)].reset_index(drop=True)\n",
    "    elif subset=='s3':\n",
    "        st = st[(st['hour']>=9)                  &(st['hour']<13)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']>=9)&(sub_test['hour']<13)].reset_index(drop=True)\n",
    "    elif subset=='s4':\n",
    "        st = st[(st['hour']>=13)                  &(st['hour']<17)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']>=13)&(sub_test['hour']<17)].reset_index(drop=True)\n",
    "    elif subset=='s5':\n",
    "        st = st[(st['hour']>=17)                  &(st['hour']<21)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']>=17)&(sub_test['hour']<21)].reset_index(drop=True)\n",
    "    elif subset=='s6':\n",
    "        st =             st[st['hour']>=21].reset_index(drop=True)\n",
    "        sub_test = sub_test[sub_test['hour']>=21].reset_index(drop=True)\n",
    "    elif subset=='e1':\n",
    "        st = st[(st['hour']>=0)                  &(st['hour']<4)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']>=0)&(sub_test['hour']<4)].reset_index(drop=True)\n",
    "    elif subset=='e2':\n",
    "        st = st[(st['hour']>=4)                  &(st['hour']<7)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']>=4)&(sub_test['hour']<7)].reset_index(drop=True)\n",
    "    elif subset=='e3':\n",
    "        st = st[(st['hour']>=7)                  &(st['hour']<10)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']>=7)&(sub_test['hour']<10)].reset_index(drop=True)\n",
    "    elif subset=='e4':\n",
    "        st = st[(st['hour']>=10)                  &(st['hour']<13)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']>=10)&(sub_test['hour']<13)].reset_index(drop=True)\n",
    "    elif subset=='e5':\n",
    "        st = st[(st['hour']>=13)                  &(st['hour']<16)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']>=13)&(sub_test['hour']<16)].reset_index(drop=True)\n",
    "    elif subset=='e6':\n",
    "        st = st[(st['hour']>=16)                  &(st['hour']<19)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']>=16)&(sub_test['hour']<19)].reset_index(drop=True)\n",
    "    elif subset=='e7':\n",
    "        st = st[(st['hour']>=19)                  &(st['hour']<22)].reset_index(drop=True)\n",
    "        sub_test = sub_test[(sub_test['hour']>=19)&(sub_test['hour']<22)].reset_index(drop=True)\n",
    "    elif subset=='e8':\n",
    "        st =             st[st['hour']>=22].reset_index(drop=True)\n",
    "        sub_test = sub_test[sub_test['hour']>=22].reset_index(drop=True)\n",
    "        \n",
    "    return st, sub_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {}\n",
    "train2 = {}\n",
    "test2 = {}\n",
    "train_cluster2 = {}\n",
    "test_cluster2 = {}\n",
    "transform_cluster = {}\n",
    "train_region2 = {}\n",
    "test_region2 = {}\n",
    "transform_region = {}\n",
    "drop_cols = ['use_electric', 'date', 'date2', 'wind_speed', 'precipitation', 'sunshine', 'operation', 'solar_power', \n",
    "             'week', 'weekend', 'weekend_holiday', 'temperature_F', 'temperature2', 'holiday', 'fold_num', 'hour2', 'cluster', 'oof_lgb', 'region']\n",
    "subsets = ['all', 'afternoon', 'morning', 'working', 'noworking', 'q1', 'q2', 'q3', 'q4', 's1', 's2', 's3', 's4', 's5', 's6', 'e1', 'e2', 'e3', 'e4', 'e5', 'e6', 'e7', 'e8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all\n",
    "for subset in subsets:\n",
    "    temp, temp2 = pd.DataFrame(), pd.DataFrame()\n",
    "    temp_transform = {}\n",
    "    for num in range(1, 61):\n",
    "        st = train[train['num']==num].reset_index(drop=True)\n",
    "        sub_test = test[test['num']==num].reset_index(drop=True)\n",
    "        \n",
    "        st, sub_test = hour_split(st, sub_test)\n",
    "        \n",
    "            \n",
    "        temp_transform[num] = MinMaxScaler()\n",
    "        temp_transform[num].fit(st[['use_electric']])\n",
    "        st['use_electric2'] = temp_transform[num].transform(st[['use_electric']])\n",
    "\n",
    "        new_col = 'mean_use_electric' \n",
    "        st[new_col] = st['weekend'].astype(str) + '_' + st['hour'].astype(str)\n",
    "        sub_test[new_col] = sub_test['weekend'].astype(str) + '_' + sub_test['hour'].astype(str)\n",
    "        sub_test[new_col] = sub_test[new_col].map(st.groupby(new_col)['use_electric'].mean())\n",
    "        st[new_col] = st[new_col].map(st.groupby(new_col)['use_electric'].mean())\n",
    "\n",
    "        st['fold_num'] = (st['day']//7)    \n",
    "        temp = pd.concat([temp, st])\n",
    "        temp2 = pd.concat([temp2, sub_test])\n",
    "\n",
    "    transform[subset] = temp_transform\n",
    "    train2[subset] = temp.reset_index(drop=True)\n",
    "    test2[subset] = temp2.reset_index(drop=True)\n",
    "\n",
    "# cluster\n",
    "for subset in subsets:\n",
    "    temp_train = {}\n",
    "    temp_test = {}\n",
    "    temp_transform = {}\n",
    "    for c in range(5):\n",
    "        temp, temp2 = pd.DataFrame(), pd.DataFrame()\n",
    "        for num in np.unique(train.loc[train['cluster']==c, 'num']):\n",
    "            st = train[train['num']==num].reset_index(drop=True)\n",
    "            sub_test = test[test['num']==num].reset_index(drop=True)\n",
    "            st, sub_test = hour_split(st, sub_test)\n",
    "                \n",
    "            temp_transform[num] = MinMaxScaler()\n",
    "            temp_transform[num].fit(st[['use_electric']])\n",
    "            st['use_electric2'] = temp_transform[num].transform(st[['use_electric']])\n",
    "\n",
    "            new_col = 'mean_use_electric' \n",
    "            st[new_col] = st['weekend'].astype(str) + '_' + st['hour'].astype(str)\n",
    "            sub_test[new_col] = sub_test['weekend'].astype(str) + '_' + sub_test['hour'].astype(str)\n",
    "            sub_test[new_col] = sub_test[new_col].map(st.groupby(new_col)['use_electric'].mean())\n",
    "            st[new_col] = st[new_col].map(st.groupby(new_col)['use_electric'].mean())\n",
    "\n",
    "            st['fold_num'] = (st['day']//7)    \n",
    "            temp = pd.concat([temp, st])\n",
    "            temp2 = pd.concat([temp2, sub_test])\n",
    "\n",
    "        temp_train[c] = temp.reset_index(drop=True)\n",
    "        temp_test[c] = temp2.reset_index(drop=True)\n",
    "    train_cluster2[subset] = temp_train\n",
    "    test_cluster2[subset] = temp_test\n",
    "    transform_cluster[subset] = temp_transform\n",
    "    \n",
    "# region\n",
    "for subset in subsets:\n",
    "    temp_train = {}\n",
    "    temp_test = {}\n",
    "    temp_transform = {}\n",
    "    for c in range(6):\n",
    "        temp, temp2 = pd.DataFrame(), pd.DataFrame()\n",
    "        for num in np.unique(train.loc[train['region']==c, 'num']):\n",
    "            st = train[train['num']==num].reset_index(drop=True)\n",
    "            sub_test = test[test['num']==num].reset_index(drop=True)\n",
    "            st, sub_test = hour_split(st, sub_test)\n",
    "\n",
    "            temp_transform[num] = MinMaxScaler()\n",
    "            temp_transform[num].fit(st[['use_electric']])\n",
    "            st['use_electric2'] = temp_transform[num].transform(st[['use_electric']])\n",
    "\n",
    "            new_col = 'mean_use_electric' \n",
    "            st[new_col] = st['weekend'].astype(str) + '_' + st['hour'].astype(str)\n",
    "            sub_test[new_col] = sub_test['weekend'].astype(str) + '_' + sub_test['hour'].astype(str)\n",
    "            sub_test[new_col] = sub_test[new_col].map(st.groupby(new_col)['use_electric'].mean())\n",
    "            st[new_col] = st[new_col].map(st.groupby(new_col)['use_electric'].mean())\n",
    "\n",
    "            st['fold_num'] = (st['day']//7)    \n",
    "            temp = pd.concat([temp, st])\n",
    "            temp2 = pd.concat([temp2, sub_test])\n",
    "\n",
    "        temp_train[c] = temp.reset_index(drop=True)\n",
    "        temp_test[c] = temp2.reset_index(drop=True)\n",
    "    train_region2[subset] = temp_train\n",
    "    test_region2[subset] = temp_test\n",
    "    transform_region[subset] = temp_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for subset in subsets:\n",
    "    print(subset)\n",
    "    train2[subset]['oof_lgb'], test2[subset]['oof_lgb'], _ = lgb_models(train2[subset], test2[subset], drop_col=drop_cols, \n",
    "                                                                           target='use_electric2', \n",
    "                                                                           category_features=['num', 'month', 'THI', 'weekend2', ],\n",
    "                                                                           learn='lgb', v=0, exp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['oof_lgb']:\n",
    "    for subset in subsets:\n",
    "        train2[subset][col+'2'] = np.concatenate([transform[subset][num].inverse_transform(train2[subset].loc[train2[subset]['num']==num, [col]]) for num in range(1, 61)])\n",
    "        test2[subset][col+'2'] = np.concatenate([transform[subset][num].inverse_transform(test2[subset].loc[test2[subset]['num']==num, [col]]) for num in range(1, 61)])\n",
    "        \n",
    "for df in [train2, test2]:\n",
    "    df['afternoon_morning'] = pd.concat([df['afternoon'], df['morning']]).sort_values(['num', 'date']).reset_index(drop=True)\n",
    "    df['working_noworking'] = pd.concat([df['working'], df['noworking']]).sort_values(['num', 'date']).reset_index(drop=True)\n",
    "    df['q1234'] = pd.concat([df['q1'], df['q2'], df['q3'], df['q4']]).sort_values(['num', 'date']).reset_index(drop=True)\n",
    "    df['s123456'] = pd.concat([df['s1'], df['s2'], df['s3'], df['s4'], df['s5'], df['s6']]).sort_values(['num', 'date']).reset_index(drop=True)\n",
    "    df['e12345678'] = pd.concat([df['e1'], df['e2'], df['e3'], df['e4'], df['e5'], df['e6'], df['e7'], df['e8']]).sort_values(['num', 'date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in ['all', 'afternoon_morning', 'working_noworking', 'q1234', 's123456', 'e12345678']:\n",
    "    print(smape(train2[subset]['oof_lgb2'], train['use_electric']))\n",
    "\n",
    "smape(np.mean([train2['all']['oof_lgb2'],\n",
    "                train2['afternoon_morning']['oof_lgb2'],\n",
    "                train2['working_noworking']['oof_lgb2'],\n",
    "                train2['q1234']['oof_lgb2'],\n",
    "                train2['s123456']['oof_lgb2'],\n",
    "                train2['e12345678']['oof_lgb2']], 0), train['use_electric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.854304032291577\n",
    "# 4.888289768844324\n",
    "# 4.840717546803809\n",
    "# 4.878037671834281\n",
    "# 4.877795888635189\n",
    "# 4.905936332216347\n",
    "# 4.666819341958758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for subset in subsets:\n",
    "    print(subset)\n",
    "    for c in range(5):\n",
    "        train_cluster2[subset][c]['oof_lgb'], test_cluster2[subset][c]['oof_lgb'], _ = lgb_models(train_cluster2[subset][c], test_cluster2[subset][c], drop_col=drop_cols, \n",
    "                                                                                                   target='use_electric2', \n",
    "                                                                                                   category_features=['num', 'month', 'THI', 'weekend2', ],\n",
    "                                                                                                   learn='lgb', v=0, exp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in subsets:\n",
    "    train_cluster2[subset] = pd.concat(train_cluster2[subset].values()).sort_values(['num', 'date']).reset_index(drop=True)\n",
    "    test_cluster2[subset] = pd.concat(test_cluster2[subset].values()).sort_values(['num', 'date']).reset_index(drop=True)\n",
    "\n",
    "for col in ['oof_lgb']:\n",
    "    for subset in subsets:\n",
    "        train_cluster2[subset][col+'2'] = np.concatenate([transform_cluster[subset][num].inverse_transform(train_cluster2[subset].loc[train_cluster2[subset]['num']==num, [col]]) for num in range(1, 61)])\n",
    "        test_cluster2[subset][col+'2'] = np.concatenate([transform_cluster[subset][num].inverse_transform(test_cluster2[subset].loc[test_cluster2[subset]['num']==num, [col]]) for num in range(1, 61)])\n",
    "\n",
    "for df in [train_cluster2, test_cluster2]:\n",
    "    df['afternoon_morning'] = pd.concat([df['afternoon'], df['morning']]).sort_values(['num', 'date']).reset_index(drop=True)\n",
    "    df['working_noworking'] = pd.concat([df['working'], df['noworking']]).sort_values(['num', 'date']).reset_index(drop=True)\n",
    "    df['q1234'] = pd.concat([df['q1'], df['q2'], df['q3'], df['q4']]).sort_values(['num', 'date']).reset_index(drop=True)\n",
    "    df['s123456'] = pd.concat([df['s1'], df['s2'], df['s3'], df['s4'], df['s5'], df['s6']]).sort_values(['num', 'date']).reset_index(drop=True)\n",
    "    df['e12345678'] = pd.concat([df['e1'], df['e2'], df['e3'], df['e4'], df['e5'], df['e6'], df['e7'], df['e8']]).sort_values(['num', 'date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in ['all', 'afternoon_morning', 'working_noworking', 'q1234', 's123456', 'e12345678']:\n",
    "    print(smape(train_cluster2[subset]['oof_lgb2'], train['use_electric']))\n",
    "\n",
    "smape(np.mean([train_cluster2['all']['oof_lgb2'],\n",
    "                train_cluster2['afternoon_morning']['oof_lgb2'],\n",
    "                train_cluster2['working_noworking']['oof_lgb2'],\n",
    "                train_cluster2['q1234']['oof_lgb2'],\n",
    "                train_cluster2['s123456']['oof_lgb2'],\n",
    "                train_cluster2['e12345678']['oof_lgb2']], 0), train['use_electric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.834800050014874\n",
    "# 4.876309745723581\n",
    "# 4.857260584692095\n",
    "# 4.914418823959304\n",
    "# 4.9192538915152175\n",
    "# 4.953230095541329\n",
    "# 4.699489300011213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for subset in subsets:\n",
    "    print(subset)\n",
    "    for c in range(6):\n",
    "        train_region2[subset][c]['oof_lgb'], test_region2[subset][c]['oof_lgb'], _ = lgb_models(train_region2[subset][c], test_region2[subset][c], drop_col=drop_cols, \n",
    "                                                                                               target='use_electric2', \n",
    "                                                                                               category_features=['num', 'month', 'THI', 'weekend2', ],\n",
    "                                                                                               learn='lgb', v=0, exp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in subsets:\n",
    "    train_region2[subset] = pd.concat(train_region2[subset].values()).sort_values(['num', 'date']).reset_index(drop=True)\n",
    "    test_region2[subset] = pd.concat(test_region2[subset].values()).sort_values(['num', 'date']).reset_index(drop=True)\n",
    "    \n",
    "for col in ['oof_lgb']:\n",
    "    for subset in subsets:\n",
    "        train_region2[subset][col+'2'] = np.concatenate([transform_region[subset][num].inverse_transform(train_region2[subset].loc[train_region2[subset]['num']==num, [col]]) for num in range(1, 61)])\n",
    "        test_region2[subset][col+'2'] = np.concatenate([transform_region[subset][num].inverse_transform(test_region2[subset].loc[test_region2[subset]['num']==num, [col]]) for num in range(1, 61)])\n",
    "        \n",
    "for df in [train_region2, test_region2]:\n",
    "    df['afternoon_morning'] = pd.concat([df['afternoon'], df['morning']]).sort_values(['num', 'date']).reset_index(drop=True)\n",
    "    df['working_noworking'] = pd.concat([df['working'], df['noworking']]).sort_values(['num', 'date']).reset_index(drop=True)\n",
    "    df['q1234'] = pd.concat([df['q1'], df['q2'], df['q3'], df['q4']]).sort_values(['num', 'date']).reset_index(drop=True)\n",
    "    df['s123456'] = pd.concat([df['s1'], df['s2'], df['s3'], df['s4'], df['s5'], df['s6']]).sort_values(['num', 'date']).reset_index(drop=True)\n",
    "    df['e12345678'] = pd.concat([df['e1'], df['e2'], df['e3'], df['e4'], df['e5'], df['e6'], df['e7'], df['e8']]).sort_values(['num', 'date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in ['all', 'afternoon_morning', 'working_noworking', 'q1234', 's123456', 'e12345678']:\n",
    "    print(smape(train_region2[subset]['oof_lgb2'], train['use_electric']))\n",
    "\n",
    "smape(np.mean([train_region2['all']['oof_lgb2'],\n",
    "                train_region2['afternoon_morning']['oof_lgb2'],\n",
    "                train_region2['working_noworking']['oof_lgb2'],\n",
    "                train_region2['q1234']['oof_lgb2'],\n",
    "                train_region2['s123456']['oof_lgb2'],\n",
    "                train_region2['e12345678']['oof_lgb2']], 0), train['use_electric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.904486164267104\n",
    "# 4.9381086017006\n",
    "# 4.8948993577088356\n",
    "# 4.9598043953166\n",
    "# 4.9428339864017445\n",
    "# 4.951370227115714\n",
    "# 4.756103473189231\n",
    "# 4.721349836159994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train2, train_cluster2, train_region2]:\n",
    "    temp = np.zeros(len(train))\n",
    "    for subset in ['all', 'afternoon_morning', 'working_noworking', 'q1234', 's123456', 'e12345678']:\n",
    "        temp += df[subset]['oof_lgb2']\n",
    "    df['all']['oof_lgb_mean'] = temp/6\n",
    "    \n",
    "for df in [test2, test_cluster2, test_region2]:\n",
    "    temp = np.zeros(len(test))\n",
    "    for subset in ['all', 'afternoon_morning', 'working_noworking', 'q1234', 's123456', 'e12345678']:\n",
    "        temp += df[subset]['oof_lgb2']\n",
    "    df['all']['oof_lgb_mean'] = temp/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('energy/sample_submission.csv')\n",
    "sub['answer_subset'] = ((np.concatenate(list(pred_lgb678.values()))*.7 + np.concatenate(list(pred_xgb678.values()))*.3)*.45 +\n",
    "                        (np.concatenate(list(pred_lgb78.values()))*.7 + np.concatenate(list(pred_xgb78.values()))*.3)*.45 +\n",
    "                        (np.concatenate(list(pred_lgb8.values()))*.7 + np.concatenate(list(pred_xgb8.values()))*.3)*.1)\n",
    "\n",
    "sub['answer_time'] = (test2['all']['oof_lgb_mean']*0.35 + \n",
    "                        test_cluster2['all']['oof_lgb_mean']*0.35 + \n",
    "                        test_region2['all']['oof_lgb_mean']*0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset models\n",
    "w1 = [1.001, 1.013, 1.001, 0.962, 0.985, 1.025, 1.0, 1.045, 0.994, 1.02 , \n",
    " 0.958, 0.983, 1.009, 0.993, 0.991, 0.989, 1.007, 0.997, 1.028, 1.03 , \n",
    " 1.029, 1.041, 1.029, 1.009, 1.011, 1.014, 1.046, 0.998, 0.969, 1.02 , \n",
    " 1.006, 1.003, 0.999, 0.967, 1.049, 1.03 , 1.006, 1.031, 1.018, 0.965, \n",
    " 0.981, 0.964, 1.007, 1.029, 1.008, 0.99 , 0.998, 1.05 , 1.038, 1.0  , \n",
    " 0.999, 0.991, 1.015, 1.021, 1.027, 1.038, 1.05 , 0.993, 0.957, 0.996]\n",
    "w2 = [i if i>1.0 else 1.0 for i in w1]\n",
    "\n",
    "sub['answer_subset'] = np.expm1(subset_best)\n",
    "sub['num'] = test['num']\n",
    "for num in range(1, 61):\n",
    "    sub.loc[sub['num']==num, 'answer_subset'] = sub.loc[sub['num']==num, 'answer_subset']*w2[num-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## time model weight\n",
    "w1 = [1.0, 1.009, 1.005, 0.981, 0.99, 1.03, 0.989, 1.049, 0.986, 1.01, 0.95,\n",
    "     0.968, 1.006, 0.984, 0.982, 0.966, 0.996, 0.96, 0.973, 1.004, 1.023,\n",
    "     1.05, 1.03, 1.0, 0.99, 1.02, 1.034, 0.956, 0.951, 0.997, 1.004, 1.002,\n",
    "     0.995, 0.95, 1.05, 1.032, 1.001, 1.033, 1.032, 0.956, 0.97, 0.95, 1.0,\n",
    "     1.033, 0.99, 0.975, 0.992, 1.048, 1.023, 0.994, 0.973, 0.98, 1.014,\n",
    "     1.025, 1.027, 1.05, 1.05, 0.974, 0.95, 0.977]\n",
    "w2 = [i+0.02 if i<0.98 else 1.0 for i in w1]\n",
    "for num in range(1, 61):\n",
    "    sub.loc[sub['num']==num, 'answer_time'] = sub.loc[sub['num']==num, 'answer_time']*w2[num-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['answer'] = sub['answer_subset']*.7 + sub['answer_time']*.3\n",
    "sub[['num_date_time', 'answer']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "dacon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
